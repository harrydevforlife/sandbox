{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1uUfQ9BHEmmpRcQ7TwR0TycxcwmOyaiC4",
      "authorship_tag": "ABX9TyMaV8w6BSAkiMi5BCo7417C",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harrydevforlife/sandbox/blob/main/pyarrow_and_fastparquet_writer_benchmark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyarrow fastparquet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8uSyJ_OPRIyD",
        "outputId": "5518b8df-245b-42d2-c336-867b51ec9d84"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (17.0.0)\n",
            "Collecting fastparquet\n",
            "  Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.10/dist-packages (from pyarrow) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2.2.2)\n",
            "Collecting cramjam>=2.3 (from fastparquet)\n",
            "  Downloading cramjam-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from fastparquet) (2024.10.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastparquet) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.0->fastparquet) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
            "Downloading fastparquet-2024.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cramjam-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cramjam, fastparquet\n",
            "Successfully installed cramjam-2.9.0 fastparquet-2024.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import fastparquet\n",
        "import time\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "def generate_sample_data(num_rows=10_000_000, num_cols=10):\n",
        "    \"\"\"\n",
        "    Generates a pandas DataFrame with random data.\n",
        "\n",
        "    Args:\n",
        "        num_rows (int): Number of rows.\n",
        "        num_cols (int): Number of columns.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Generated DataFrame.\n",
        "    \"\"\"\n",
        "    data = {\n",
        "        f'col_{i}': np.random.randn(num_rows) for i in range(num_cols)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "    return df\n",
        "\n",
        "def write_parquet_pyarrow(df, file_path, compression='snappy', use_threads=True):\n",
        "    \"\"\"\n",
        "    Writes DataFrame to Parquet using PyArrow.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Data to write.\n",
        "        file_path (str): Destination file path.\n",
        "        compression (str): Compression algorithm.\n",
        "        use_threads (bool): Whether to use multi-threading.\n",
        "    \"\"\"\n",
        "    table = pa.Table.from_pandas(df)\n",
        "    pq.write_table(table, file_path, compression=compression)\n",
        "\n",
        "def write_parquet_fastparquet(df, file_path, compression='SNAPPY', compression_level=None):\n",
        "    \"\"\"\n",
        "    Writes DataFrame to Parquet using FastParquet.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Data to write.\n",
        "        file_path (str): Destination file path.\n",
        "        compression (str): Compression algorithm.\n",
        "        compression_level (int, optional): Compression level.\n",
        "    \"\"\"\n",
        "    fastparquet.write(file_path, df, compression=compression)\n",
        "\n",
        "def benchmark_write(func, *args, **kwargs):\n",
        "    \"\"\"\n",
        "    Benchmarks the time taken by a function to execute.\n",
        "\n",
        "    Args:\n",
        "        func (callable): Function to benchmark.\n",
        "        *args: Positional arguments for the function.\n",
        "        **kwargs: Keyword arguments for the function.\n",
        "\n",
        "    Returns:\n",
        "        float: Time taken in seconds.\n",
        "    \"\"\"\n",
        "    start_time = time.time()\n",
        "    func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time\n",
        "\n",
        "def run_benchmark(df, num_runs=3, compression='snappy'):\n",
        "    \"\"\"\n",
        "    Runs the benchmark for both PyArrow and FastParquet.\n",
        "\n",
        "    Args:\n",
        "        df (pd.DataFrame): Data to write.\n",
        "        num_runs (int): Number of times to run each benchmark.\n",
        "        compression (str): Compression algorithm to use.\n",
        "\n",
        "    Returns:\n",
        "        dict: Average write times for each library.\n",
        "    \"\"\"\n",
        "    results = {'pyarrow': [], 'fastparquet': []}\n",
        "\n",
        "    for run in range(1, num_runs + 1):\n",
        "        print(f\"\\nRun {run} of {num_runs}:\")\n",
        "\n",
        "        with tempfile.TemporaryDirectory() as tmpdirname:\n",
        "            # Define file paths\n",
        "            pyarrow_file = os.path.join(tmpdirname, 'data_pyarrow.parquet')\n",
        "            fastparquet_file = os.path.join(tmpdirname, 'data_fastparquet.parquet')\n",
        "\n",
        "            # Benchmark PyArrow\n",
        "            time_pyarrow = benchmark_write(\n",
        "                write_parquet_pyarrow,\n",
        "                df,\n",
        "                pyarrow_file,\n",
        "                compression=compression,\n",
        "                use_threads=True\n",
        "            )\n",
        "            results['pyarrow'].append(time_pyarrow)\n",
        "            print(f\"PyArrow write time: {time_pyarrow:.2f} seconds\")\n",
        "\n",
        "            # Benchmark FastParquet\n",
        "            time_fastparquet = benchmark_write(\n",
        "                write_parquet_fastparquet,\n",
        "                df,\n",
        "                fastparquet_file,\n",
        "                compression=compression.upper()\n",
        "            )\n",
        "            results['fastparquet'].append(time_fastparquet)\n",
        "            print(f\"FastParquet write time: {time_fastparquet:.2f} seconds\")\n",
        "\n",
        "    # Calculate average times\n",
        "    avg_pyarrow = sum(results['pyarrow']) / num_runs\n",
        "    avg_fastparquet = sum(results['fastparquet']) / num_runs\n",
        "\n",
        "    return {\n",
        "        'PyArrow Average Time (s)': avg_pyarrow,\n",
        "        'FastParquet Average Time (s)': avg_fastparquet\n",
        "    }\n",
        "\n",
        "def main():\n",
        "    # Parameters\n",
        "    NUM_ROWS = 10_000_000  # 10 million rows\n",
        "    NUM_COLS = 10          # 10 columns\n",
        "    NUM_RUNS = 10          # Number of benchmark runs\n",
        "    COMPRESSION = 'snappy' # Compression algorithm ('snappy', 'gzip', 'brotli', etc.)\n",
        "\n",
        "    print(\"Generating sample data...\")\n",
        "    df = generate_sample_data(num_rows=NUM_ROWS, num_cols=NUM_COLS)\n",
        "    print(f\"DataFrame with {NUM_ROWS} rows and {NUM_COLS} columns generated.\")\n",
        "\n",
        "    print(\"\\nStarting benchmark...\")\n",
        "    results = run_benchmark(df, num_runs=NUM_RUNS, compression=COMPRESSION)\n",
        "\n",
        "    print(\"\\nBenchmark Results:\")\n",
        "    for lib, avg_time in results.items():\n",
        "        print(f\"{lib}: {avg_time:.2f} seconds on average over {NUM_RUNS} runs\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTo_ThjxytkD",
        "outputId": "c1eb2016-8b91-40c4-9fd4-59bc4445bac1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating sample data...\n",
            "DataFrame with 10000000 rows and 10 columns generated.\n",
            "\n",
            "Starting benchmark...\n",
            "\n",
            "Run 1 of 10:\n",
            "PyArrow write time: 7.24 seconds\n",
            "FastParquet write time: 13.07 seconds\n",
            "\n",
            "Run 2 of 10:\n",
            "PyArrow write time: 10.86 seconds\n",
            "FastParquet write time: 8.50 seconds\n",
            "\n",
            "Run 3 of 10:\n",
            "PyArrow write time: 11.34 seconds\n",
            "FastParquet write time: 8.52 seconds\n",
            "\n",
            "Run 4 of 10:\n",
            "PyArrow write time: 12.72 seconds\n",
            "FastParquet write time: 15.45 seconds\n",
            "\n",
            "Run 5 of 10:\n",
            "PyArrow write time: 10.24 seconds\n",
            "FastParquet write time: 11.96 seconds\n",
            "\n",
            "Run 6 of 10:\n",
            "PyArrow write time: 13.98 seconds\n",
            "FastParquet write time: 5.38 seconds\n",
            "\n",
            "Run 7 of 10:\n",
            "PyArrow write time: 10.45 seconds\n",
            "FastParquet write time: 9.73 seconds\n",
            "\n",
            "Run 8 of 10:\n",
            "PyArrow write time: 9.45 seconds\n",
            "FastParquet write time: 12.32 seconds\n",
            "\n",
            "Run 9 of 10:\n",
            "PyArrow write time: 10.53 seconds\n",
            "FastParquet write time: 11.04 seconds\n",
            "\n",
            "Run 10 of 10:\n",
            "PyArrow write time: 11.65 seconds\n",
            "FastParquet write time: 9.36 seconds\n",
            "\n",
            "Benchmark Results:\n",
            "PyArrow Average Time (s): 10.85 seconds on average over 10 runs\n",
            "FastParquet Average Time (s): 10.53 seconds on average over 10 runs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2kL0ITPsRGZM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}